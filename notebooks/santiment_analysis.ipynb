{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренировочный корпус, состоящий из 114,911 положительных, 111,923 отрицательных записей с платформы микроблогинга Twitter.\n",
    "http://study.mokoron.com/\n",
    "\n",
    "– id: уникальный номер сообщения в системе twitter;\n",
    "\n",
    "– tdate: дата публикации сообщения (твита);\n",
    "\n",
    "– tname: имя пользователя, опубликовавшего сообщение;\n",
    "\n",
    "– ttext:  текст сообщения (твита);\n",
    "\n",
    "– ttype: поле в котором в дальнейшем будет указано к кому классу относится твит (положительный, отрицательный, нейтральный);\n",
    "\n",
    "– trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;\n",
    "\n",
    "– trtv: ???\n",
    "\n",
    "– tfav: число сколько раз данное сообщение было добавлено в избранное другими пользователями;\n",
    "\n",
    "– tstcount: число всех сообщений пользователя в сети twitter;\n",
    "\n",
    "– tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);\n",
    "\n",
    "– tfrien: количество друзей пользователя (те люди, которых читает пользователь);\n",
    "\n",
    "– listcount: количество листов-подписок в которые добавлен твиттер-пользователь.\n",
    "\n",
    "Рубцова Ю. Автоматическое построение и анализ корпуса коротких текстов (постов микроблогов) для задачи разработки и тренировки тонового классификатора //Инженерия знаний и технологии семантического веба. – 2012. – Т. 1. – С. 109-116."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = ['id', 'tdate', 'tname', 'ttext', 'ttype', 'trep', 'trtv',\n",
    "         'tfav','tstcount', 'tfol', 'tfrien', 'listcount']\n",
    "positive = pd.read_csv(\"../data/positive.csv\", sep=';', names=names)\n",
    "negative = pd.read_csv(\"../data/negative.csv\", sep=';', names=names)\n",
    "data = pd.concat([positive[:110000], negative[:110000]])\n",
    "names = list(filter(lambda x: x not in ['ttext', 'ttype'], names))\n",
    "data = data.drop(columns=names)\n",
    "data.loc[data['ttype'] == -1, 'ttype'] = 0\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                               ttext  ttype\n",
       " 0  RT @Jmurkaa: Короч ребят фото гавно,и у тетки ...      1\n",
       " 1  пт 13\\nи контрольный тест\\nсилы зла, я на ваше...      1\n",
       " 2  Не люблю я геометрию:( еще а зачету готовиться...      0\n",
       " 3  @JulJulianapai  Здравствуйте, Юлиана! Смейтесь...      1\n",
       " 4  @safirova а сами то , микс из какашек и говняш...      1, (220000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = list(data['ttext']), list(data['ttype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "lemmatizer = Mystem()\n",
    "X = list(map(lemmatizer.lemmatize, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "with open('../data/mystopwords') as f:\n",
    "    stop_words = [w.replace('\\n', '') for w in f]\n",
    "\n",
    "tmp_func = lambda tokens: [token for token in tokens if token not in stop_words and len(token) > 3]\n",
    "\n",
    "X = list(map(tmp_func, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filtring_data(list_string):\n",
    "    pattern = u\"[а-яА-ЯёЁ]+\"\n",
    "    tmp_list = list(filter(lambda x: re.fullmatch(pattern, x), list_string))\n",
    "    regex = re.compile(r'^.*(.)(\\1)(\\1).*$')\n",
    "    return list(filter(lambda x: not re.fullmatch(regex, x), tmp_list))\n",
    "X = list(map(filtring_data, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['короча', 'ребята', 'фото', 'гавно', 'тетка', 'жопа', 'гавно', 'просто', 'видно'], ['контрольный', 'тест', 'сила', 'сторона'], ['любить', 'геометрия', 'зачет', 'готовиться'], ['здравствовать', 'юлиана', 'смеяться', 'пять', 'минута', 'смех', 'прибавлять', 'жизнь', 'студент', 'равноценный', 'стакан', 'сметана'], ['микс', 'какашка', 'говняшка']]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=15, max_df=0.0006, max_features=10000)\n",
    "#vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=10, max_df=0.0006, max_features=10000)\n",
    "bag_of_words = vectorizer.fit_transform(list(map(\" \".join, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['аарон',\n",
       " 'ааха',\n",
       " 'аахах',\n",
       " 'аахахах',\n",
       " 'ааххах',\n",
       " 'абзац',\n",
       " 'абонент',\n",
       " 'аваад',\n",
       " 'авария',\n",
       " 'аватар',\n",
       " 'аватарка',\n",
       " 'авахгуй',\n",
       " 'авахгуй баярлуулна',\n",
       " 'август',\n",
       " 'австрия',\n",
       " 'авто',\n",
       " 'автобус ехать',\n",
       " 'автограф',\n",
       " 'автоматически',\n",
       " 'автомобиль',\n",
       " 'автор',\n",
       " 'авторитет',\n",
       " 'авторский',\n",
       " 'автошкола',\n",
       " 'агент',\n",
       " 'агентство',\n",
       " 'агрессивный',\n",
       " 'агрессия',\n",
       " 'агутин',\n",
       " 'адам']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=3, n_iter=5,\n",
       "             random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tSVD = TruncatedSVD(n_components=3)\n",
    "tSVD.fit(bag_of_words.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 180000\n",
    "X_train, X_test = tSVD.components_.T[:n_train], tSVD.components_.T[n_train:]\n",
    "#X_train, X_test = bag_of_words.toarray()[:n_train], bag_of_words.toarray()[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.50      0.89      0.64     19922\n",
      "    Positive       0.52      0.12      0.19     20078\n",
      "\n",
      "    accuracy                           0.50     40000\n",
      "   macro avg       0.51      0.50      0.42     40000\n",
      "weighted avg       0.51      0.50      0.42     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "fitted_gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "report = classification_report(y_test, fitted_gnb.predict(X_test), target_names=['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.55      0.68      0.61     19922\n",
      "    Positive       0.59      0.45      0.51     20078\n",
      "\n",
      "    accuracy                           0.56     40000\n",
      "   macro avg       0.57      0.57      0.56     40000\n",
      "weighted avg       0.57      0.56      0.56     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "fitted_knc = knc.fit(X_train, y_train)\n",
    "\n",
    "report = classification_report(y_test, fitted_knc.predict(X_test), target_names=['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.54      0.71      0.61     19922\n",
      "    Positive       0.58      0.40      0.48     20078\n",
      "\n",
      "    accuracy                           0.56     40000\n",
      "   macro avg       0.56      0.56      0.54     40000\n",
      "weighted avg       0.56      0.56      0.54     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=20, n_jobs=-1)\n",
    "fitted_knc = knc.fit(X_train, y_train)\n",
    "\n",
    "report = classification_report(y_test, fitted_knc.predict(X_test), target_names=['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.52      0.62      0.57     19922\n",
      "    Positive       0.54      0.43      0.48     20078\n",
      "\n",
      "    accuracy                           0.53     40000\n",
      "   macro avg       0.53      0.53      0.52     40000\n",
      "weighted avg       0.53      0.53      0.52     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "fitted_rfc = rfc.fit(X_train, y_train)\n",
    "\n",
    "report = classification_report(y_test, fitted_rfc.predict(X_test), target_names=['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ficusss_g53/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "fitted_svc = svc.fit(X_train, y_train)\n",
    "\n",
    "report = classification_report(y_test, fitted_svc.predict(X_test), target_names=['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
